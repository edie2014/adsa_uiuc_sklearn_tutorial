{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining and parameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we study how to chain different estimators to form one end-to-end model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             categories=('rec.sport.hockey', 'soc.religion.christian',\n",
    "                                         'rec.motorcycles', 'rec.sport.baseball', 'sci.crypt'),\n",
    "                             remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs, y = dataset['data'], dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instead of doing just one train/validation step, we will do cross-validation\n",
    "\n",
    "`sklearn.model_selection.cross_val_score` and `sklearn.model_selection.*SearchCV` do everything for us!\n",
    "\n",
    "However, we need to pass then an \"estimator\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layering transformers and classifiers: The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "default_tokenizer = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "\n",
    "def number_aware_tokenizer(doc):\n",
    "    # Start off with the default tokenizer\n",
    "    toks = default_tokenizer.findall(doc)\n",
    "    # replace tokens that start with numbers with a custom marker\n",
    "    toks = [\n",
    "        \"#NBR\" if t[0].isdigit() else t  # substitute numeric-starting tokens\n",
    "        for t in toks\n",
    "        if t.isalnum()  # drop non-alphanumeric tokens\n",
    "    ]\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline([(name_1, object_1), (name_2, object_2), ...])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=5,\n",
    "                             max_df=0.11,\n",
    "                             tokenizer=number_aware_tokenizer)),\n",
    "    ('clf', LogisticRegression(multi_class='multinomial',\n",
    "                               solver='lbfgs'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85766247  0.82267921  0.83422012]\n",
      "Mean CV F1: 0.84\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(pipe, docs, y, scoring='f1_macro', cv=3)\n",
    "\n",
    "print(cv_scores)\n",
    "print(\"Mean CV F1: {:.2f}\".format(cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'vect__min_df': (1, 5, 10),\n",
    "        'vect__max_df': (0.10, 0.11, 0.12),\n",
    "        'clf__C': (0.01, 0.1, 1, 10, 100)\n",
    "    },\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=2,\n",
    "    n_iter=15,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.11, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "          fit_params={}, iid=True, n_iter=15, n_jobs=2,\n",
       "          param_distributions={'clf__C': (0.01, 0.1, 1, 10, 100), 'vect__max_df': (0.1, 0.11, 0.12), 'vect__min_df': (1, 5, 10)},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(docs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85600500561149673"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 0.1, 'vect__max_df': 0.1, 'vect__min_df': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.80194, std: 0.01618, params: {'clf__C': 100, 'vect__max_df': 0.12, 'vect__min_df': 10},\n",
       " mean: 0.83715, std: 0.01644, params: {'clf__C': 0.01, 'vect__max_df': 0.1, 'vect__min_df': 1},\n",
       " mean: 0.83489, std: 0.01454, params: {'clf__C': 0.01, 'vect__max_df': 0.11, 'vect__min_df': 1},\n",
       " mean: 0.83150, std: 0.01084, params: {'clf__C': 100, 'vect__max_df': 0.11, 'vect__min_df': 1},\n",
       " mean: 0.85601, std: 0.01921, params: {'clf__C': 0.1, 'vect__max_df': 0.1, 'vect__min_df': 1},\n",
       " mean: 0.83933, std: 0.01757, params: {'clf__C': 1, 'vect__max_df': 0.1, 'vect__min_df': 5},\n",
       " mean: 0.84664, std: 0.01487, params: {'clf__C': 1, 'vect__max_df': 0.11, 'vect__min_df': 1},\n",
       " mean: 0.82898, std: 0.01522, params: {'clf__C': 100, 'vect__max_df': 0.1, 'vect__min_df': 1},\n",
       " mean: 0.82374, std: 0.01546, params: {'clf__C': 1, 'vect__max_df': 0.11, 'vect__min_df': 10},\n",
       " mean: 0.83044, std: 0.01619, params: {'clf__C': 0.01, 'vect__max_df': 0.12, 'vect__min_df': 1},\n",
       " mean: 0.84719, std: 0.01323, params: {'clf__C': 1, 'vect__max_df': 0.12, 'vect__min_df': 1},\n",
       " mean: 0.85301, std: 0.01796, params: {'clf__C': 0.1, 'vect__max_df': 0.11, 'vect__min_df': 1},\n",
       " mean: 0.83190, std: 0.01637, params: {'clf__C': 0.01, 'vect__max_df': 0.1, 'vect__min_df': 5},\n",
       " mean: 0.79675, std: 0.01847, params: {'clf__C': 100, 'vect__max_df': 0.1, 'vect__min_df': 10},\n",
       " mean: 0.83284, std: 0.01400, params: {'clf__C': 0.1, 'vect__max_df': 0.12, 'vect__min_df': 10}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protip:** when using `RandomizedSearchCV`, you can (and **should**) specify random distributions instead of fixed parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint, expon, uniform\n",
    "\n",
    "better_search = RandomizedSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        'vect__min_df': randint(1, 11),\n",
    "        'vect__max_df': uniform(0.05, 0.15),\n",
    "        'clf__C': expon()\n",
    "    },\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=2,\n",
    "    n_iter=15,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.11, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "          fit_params={}, iid=True, n_iter=15, n_jobs=2,\n",
       "          param_distributions={'clf__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f180f53f4e0>, 'vect__max_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f180f44db00>, 'vect__min_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f180f442c88>},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "better_search.fit(docs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85170190648496569"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 15 iterations, this does not make much difference. But in the long run, it allows you to explore much more. *(And you **should** run this much more!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#better_search.set_params(n_iter=100)\n",
    "#better_search.fit(docs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85170190648496569"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1.0214318863920728,\n",
       " 'vect__max_df': 0.07150299311135697,\n",
       " 'vect__min_df': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a topic model to the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "pipe_topic = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=5,\n",
    "                             max_df=0.11,\n",
    "                             tokenizer=number_aware_tokenizer)),\n",
    "    ('topic', LatentDirichletAllocation(n_topics=20, max_iter=20, random_state=0)),\n",
    "    ('clf', LogisticRegression(multi_class='multinomial',\n",
    "                               solver='lbfgs'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8238608   0.81820247  0.79068165]\n",
      "Mean CV F1: 0.81\n"
     ]
    }
   ],
   "source": [
    "# without optimizing the hyperparameters\n",
    "\n",
    "cv_scores_topic = cross_val_score(pipe_topic, docs, y, scoring='f1_macro', cv=3)\n",
    "\n",
    "print(cv_scores_topic)\n",
    "print(\"Mean CV F1: {:.2f}\".format(cv_scores_topic.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_topic = RandomizedSearchCV(\n",
    "    pipe_topic,\n",
    "    {\n",
    "        'vect__min_df': randint(1, 11),\n",
    "        'vect__max_df': uniform(0.05, 0.15),\n",
    "        'topic__n_topics': randint(20, 40),\n",
    "        'clf__C': expon()\n",
    "    },\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    n_jobs=1,\n",
    "    n_iter=3,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.11, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri...enalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "          fit_params={}, iid=True, n_iter=3, n_jobs=1,\n",
       "          param_distributions={'topic__n_topics': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f180df585f8>, 'clf__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f180df58fd0>, 'vect__max_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f180de1f5c0>, 'vect__min_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f180ddef358>},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          scoring='f1_macro', verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "search_topic.fit(docs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82924341532224755"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_topic.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1.8789640641973517,\n",
       " 'topic__n_topics': 39,\n",
       " 'vect__max_df': 0.14688411695999842,\n",
       " 'vect__min_df': 5}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_topic.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search_topic.set_params(n_iter=30)\n",
    "# search_topic.fit(docs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search_topic.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82924341532224755"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_topic.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When satisfied, (and no sooner!), we can evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                                  subset='test',\n",
    "                                  categories=('rec.sport.hockey', 'soc.religion.christian',\n",
    "                                              'rec.motorcycles', 'rec.sport.baseball', 'sci.crypt'),\n",
    "                                  remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_docs, test_y = test_dataset.data, test_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/code/scikit-learn/sklearn/utils/deprecation.py:52: DeprecationWarning: Class ChangedBehaviorWarning is deprecated; ChangedBehaviorWarning has been moved into the sklearn.exceptions module. It will not be available here from version 0.19\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/vlad/code/scikit-learn/sklearn/model_selection/_search.py:424: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in RandomizedSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n",
      "/home/vlad/code/scikit-learn/sklearn/utils/deprecation.py:52: DeprecationWarning: Class ChangedBehaviorWarning is deprecated; ChangedBehaviorWarning has been moved into the sklearn.exceptions module. It will not be available here from version 0.19\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words test F1: 0.85\n",
      "Topic model test F1: 0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"Bag-of-words test F1: {:.2f}\".format(better_search.score(test_docs, test_y)))\n",
    "print(\"Topic model test F1: {:.2f}\".format(search_topic.score(test_docs, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
